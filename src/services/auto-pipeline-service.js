/**
 * ROM Agent - Auto Pipeline Service
 * Orquestra√ß√£o autom√°tica: decide quando usar Pipeline vs Modelo √önico
 *
 * FILOSOFIA:
 * - Modelo √∫nico = 90% dos casos (mais eficiente)
 * - Pipeline multi-agent = Casos excepc

ionais complexos
 * - Decis√£o autom√°tica baseada em contexto
 * - Transpar√™ncia total para o usu√°rio
 *
 * @version 2.5.0
 */

import modelSelectorService from './model-selector-service.js';
import { conversar } from '../modules/bedrock.js';

class AutoPipelineService {
  constructor() {
    this.pipelineConfig = {
      // Configura√ß√£o do pipeline de 4 est√°gios
      stages: [
        {
          id: 'extra√ß√£o',
          modelo: 'haiku-4.5',
          prompt: 'Extraia e organize as informa√ß√µes principais do(s) documento(s)',
          maxTokens: 4096
        },
        {
          id: 'an√°lise',
          modelo: 'sonnet-4.5',
          prompt: 'Analise criticamente as informa√ß√µes extra√≠das',
          maxTokens: 200000
        },
        {
          id: 'fundamenta√ß√£o',
          modelo: 'deepseek-r1',
          prompt: 'Desenvolva fundamenta√ß√£o jur√≠dica completa',
          maxTokens: 16384
        },
        {
          id: 'reda√ß√£o',
          modelo: 'opus-4.5',
          prompt: 'Redija a pe√ßa final com m√°xima qualidade',
          maxTokens: 32000
        }
      ]
    };
  }

  /**
   * Processar automaticamente com a melhor estrat√©gia
   *
   * @param {object} request - Requisi√ß√£o do usu√°rio
   * @returns {Promise<object>} Resposta processada
   */
  async process(request) {
    const {
      prompt,
      tipo = null,
      documentos = [],
      prioridade = 'equilibrado',
      forcePipeline = false,
      forceModel = null,
      systemPrompt = null,
      historico = []
    } = request;

    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    // ETAPA 1: SELE√á√ÉO AUTOM√ÅTICA DE ESTRAT√âGIA
    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    const selecao = modelSelectorService.selectModel({
      tipo,
      prompt,
      documentos,
      prioridade,
      forcePipeline,
      forceModel
    });

    console.log(`ü§ñ [AutoPipeline] Estrat√©gia selecionada:`);
    console.log(`   Modelo: ${selecao.modeloNome}`);
    console.log(`   Voca√ß√£o: ${selecao.vocacao}`);
    console.log(`   Motivo: ${selecao.motivo}`);
    console.log(`   Pipeline: ${selecao.usarPipeline ? 'SIM' : 'N√ÉO'}`);
    console.log(`   Confian√ßa: ${selecao.confianca}%`);

    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    // ETAPA 2: EXECU√á√ÉO
    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    let resultado;

    if (selecao.usarPipeline) {
      // Usar pipeline multi-agent (raro)
      resultado = await this.executePipeline({
        prompt,
        tipo,
        documentos,
        systemPrompt,
        historico
      });
    } else {
      // Usar modelo √∫nico (padr√£o - 90% dos casos)
      resultado = await this.executeSingleModel({
        prompt,
        modelo: selecao.modelo,
        modeloNome: selecao.modeloNome,
        systemPrompt,
        historico,
        maxTokens: selecao.metadata.tokens
      });
    }

    // Adicionar metadados da sele√ß√£o
    resultado.selecao = {
      estrategia: selecao.usarPipeline ? 'pipeline' : 'modelo-unico',
      modelo: selecao.modeloNome,
      vocacao: selecao.vocacao,
      motivo: selecao.motivo,
      confianca: selecao.confianca,
      custoRelativo: selecao.metadata.custoRelativo,
      qualidade: selecao.metadata.qualidade
    };

    return resultado;
  }

  /**
   * Executar com modelo √∫nico (PADR√ÉO - 90% dos casos)
   */
  async executeSingleModel(config) {
    const {
      prompt,
      modelo,
      modeloNome,
      systemPrompt,
      historico,
      maxTokens
    } = config;

    console.log(`‚ú® [AutoPipeline] Executando com modelo √∫nico: ${modeloNome}`);

    const startTime = Date.now();

    const resposta = await conversar(prompt, {
      modelo,
      systemPrompt,
      historico,
      maxTokens,
      enableTools: true  // Tools sempre habilitadas
    });

    const endTime = Date.now();
    const duracao = endTime - startTime;

    console.log(`‚úÖ [AutoPipeline] Conclu√≠do em ${(duracao / 1000).toFixed(1)}s`);

    return {
      sucesso: resposta.sucesso,
      resposta: resposta.resposta,
      modelo: modeloNome,
      estrategia: 'modelo-unico',
      duracao,
      uso: resposta.uso,
      toolsUsadas: resposta.toolsUsadas,
      raciocinio: resposta.raciocinio
    };
  }

  /**
   * Executar pipeline multi-agent (EXCE√á√ÉO - 10% dos casos)
   */
  async executePipeline(config) {
    const {
      prompt,
      tipo,
      documentos,
      systemPrompt,
      historico
    } = config;

    console.log(`üîÑ [AutoPipeline] Executando pipeline multi-agent (4 est√°gios)`);

    const startTime = Date.now();
    const resultados = [];
    let contextoAcumulado = prompt;

    // Executar cada est√°gio do pipeline
    for (const [index, stage] of this.pipelineConfig.stages.entries()) {
      console.log(`   Est√°gio ${index + 1}/4: ${stage.id} (${stage.modelo})`);

      const stageStartTime = Date.now();

      // Construir prompt do est√°gio
      const stagePrompt = this.buildStagePrompt(stage, contextoAcumulado, tipo);

      // Executar est√°gio
      const resposta = await conversar(stagePrompt, {
        modelo: stage.modelo,
        systemPrompt,
        historico: index === 0 ? historico : [],  // Hist√≥rico s√≥ no primeiro
        maxTokens: stage.maxTokens,
        enableTools: index === 0  // Tools apenas no primeiro est√°gio
      });

      const stageDuracao = Date.now() - stageStartTime;

      // Armazenar resultado do est√°gio
      resultados.push({
        estagio: stage.id,
        modelo: stage.modelo,
        resposta: resposta.resposta,
        duracao: stageDuracao,
        tokens: resposta.uso
      });

      // Acumular contexto para pr√≥ximo est√°gio
      contextoAcumulado = resposta.resposta;

      console.log(`   ‚úÖ ${stage.id} conclu√≠do em ${(stageDuracao / 1000).toFixed(1)}s`);
    }

    const endTime = Date.now();
    const duracaoTotal = endTime - startTime;

    console.log(`‚úÖ [AutoPipeline] Pipeline conclu√≠do em ${(duracaoTotal / 1000).toFixed(1)}s`);

    // Resposta final √© do √∫ltimo est√°gio (reda√ß√£o)
    const respostaFinal = resultados[resultados.length - 1].resposta;

    return {
      sucesso: true,
      resposta: respostaFinal,
      modelo: 'pipeline-multi-agent',
      estrategia: 'pipeline',
      duracao: duracaoTotal,
      estagios: resultados,
      uso: {
        tokensEntrada: resultados.reduce((sum, r) => sum + (r.tokens?.tokensEntrada || 0), 0),
        tokensSaida: resultados.reduce((sum, r) => sum + (r.tokens?.tokensSaida || 0), 0),
        tokensTotal: resultados.reduce((sum, r) => sum + (r.tokens?.tokensTotal || 0), 0)
      }
    };
  }

  /**
   * Construir prompt espec√≠fico para cada est√°gio do pipeline
   */
  buildStagePrompt(stage, contexto, tipo) {
    let prompt = '';

    switch (stage.id) {
      case 'extra√ß√£o':
        prompt = `${stage.prompt}:\n\n${contexto}`;
        break;

      case 'an√°lise':
        prompt = `${stage.prompt}. Informa√ß√µes extra√≠das:\n\n${contexto}`;
        break;

      case 'fundamenta√ß√£o':
        prompt = `${stage.prompt} para ${tipo || 'a pe√ßa judicial'}. An√°lise:\n\n${contexto}`;
        break;

      case 'reda√ß√£o':
        prompt = `${stage.prompt}. Fundamenta√ß√£o:\n\n${contexto}`;
        break;

      default:
        prompt = `${stage.prompt}:\n\n${contexto}`;
    }

    return prompt;
  }

  /**
   * Processar em modo streaming (para UI em tempo real)
   */
  async processStream(request, onChunk) {
    // TODO: Implementar streaming
    console.warn('‚ö†Ô∏è Streaming ainda n√£o implementado, usando processamento normal');
    return this.process(request);
  }

  /**
   * Obter estat√≠sticas de uso (futuro)
   */
  async getStats() {
    return {
      totalProcessado: 0,
      modeloUnicoUsado: 0,
      pipelineUsado: 0,
      tempoMedioModeloUnico: 0,
      tempoMedioPipeline: 0,
      economiaTokens: 0,
      message: 'Estat√≠sticas ser√£o implementadas em vers√£o futura'
    };
  }

  /**
   * For√ßar uso de modelo espec√≠fico (override manual)
   */
  async processWithModel(prompt, modelo, options = {}) {
    return this.process({
      prompt,
      forceModel: modelo,
      forcePipeline: false,
      ...options
    });
  }

  /**
   * For√ßar uso de pipeline (override manual)
   */
  async processWithPipeline(prompt, tipo, options = {}) {
    return this.process({
      prompt,
      tipo,
      forcePipeline: true,
      ...options
    });
  }
}

// Singleton
const autoPipelineService = new AutoPipelineService();

export default autoPipelineService;
