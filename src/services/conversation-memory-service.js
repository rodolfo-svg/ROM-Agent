/**
 * Conversation Memory Service - Sistema de MemÃ³ria HierÃ¡rquica AvanÃ§ada
 *
 * SUPERIOR ao claude.ai com 3 nÃ­veis de memÃ³ria:
 * 1. SHORT-TERM: Ãšltimas 100 mensagens (contexto completo)
 * 2. MEDIUM-TERM: Resumos das Ãºltimas 500 mensagens
 * 3. LONG-TERM: Ãndice semÃ¢ntico de TODAS conversas anteriores
 *
 * Features:
 * - RecuperaÃ§Ã£o automÃ¡tica de contexto de conversas passadas
 * - CompressÃ£o inteligente preservando informaÃ§Ãµes crÃ­ticas
 * - Busca semÃ¢ntica cross-conversacional
 * - Cache de resumos para performance
 *
 * @version 3.0.0
 * @since WS6 - Advanced Memory System
 */

import { conversarStream } from '../modules/bedrock.js';
import { logger } from '../utils/logger.js';
import * as ConversationRepository from '../repositories/conversation-repository.js';
import semanticSearchService from './semantic-search-service.js';

/**
 * ConfiguraÃ§Ã£o de limites de memÃ³ria
 */
const MEMORY_LIMITS = {
  // MemÃ³ria de curto prazo: contexto completo
  shortTerm: {
    maxMessages: 100,        // vs 30 atual, vs ~40 claude.ai
    maxTokens: 150000,       // ~150k tokens de contexto
    description: 'Ãšltimas mensagens com contexto completo'
  },

  // MemÃ³ria de mÃ©dio prazo: resumos compactados
  mediumTerm: {
    maxMessages: 500,        // AtÃ© 500 mensagens resumidas
    maxTokens: 50000,        // ~50k tokens de resumos
    compressionRatio: 0.2,   // Comprimir para 20% do tamanho original
    description: 'Resumos das mensagens mais antigas'
  },

  // MemÃ³ria de longo prazo: Ã­ndice semÃ¢ntico
  longTerm: {
    maxConversations: 1000,  // AtÃ© 1000 conversas indexadas
    maxTokens: 20000,        // ~20k tokens de Ã­ndices
    description: 'Ãndice de todas conversas anteriores'
  }
};

/**
 * Classe principal do serviÃ§o de memÃ³ria
 */
export class ConversationMemoryService {
  constructor() {
    this.summaryCache = new Map(); // Cache de resumos
    this.indexCache = new Map();   // Cache de Ã­ndices semÃ¢nticos
  }

  /**
   * Construir contexto hierÃ¡rquico para uma conversa
   *
   * @param {string} conversationId - ID da conversa atual
   * @param {string} userId - ID do usuÃ¡rio
   * @param {string} currentMessage - Mensagem atual do usuÃ¡rio
   * @returns {Promise<Object>} Contexto hierÃ¡rquico completo
   */
  async buildHierarchicalContext(conversationId, userId, currentMessage) {
    const startTime = Date.now();

    try {
      // 1. MEMÃ“RIA DE CURTO PRAZO: Ãšltimas 100 mensagens
      const shortTermMemory = await this.getShortTermMemory(conversationId);

      // 2. MEMÃ“RIA DE MÃ‰DIO PRAZO: Resumos das mensagens antigas
      const mediumTermMemory = await this.getMediumTermMemory(conversationId);

      // 3. MEMÃ“RIA DE LONGO PRAZO: Contexto de conversas anteriores relevantes
      const longTermMemory = await this.getLongTermMemory(userId, currentMessage);

      // 4. Calcular estatÃ­sticas
      const stats = this.calculateMemoryStats(shortTermMemory, mediumTermMemory, longTermMemory);

      const totalTime = Date.now() - startTime;

      logger.info('[ConversationMemory] Contexto hierÃ¡rquico construÃ­do', {
        conversationId,
        userId,
        stats,
        totalTime: `${totalTime}ms`
      });

      return {
        shortTerm: shortTermMemory,
        mediumTerm: mediumTermMemory,
        longTerm: longTermMemory,
        stats,
        metadata: {
          buildTime: totalTime,
          timestamp: new Date().toISOString()
        }
      };
    } catch (error) {
      logger.error('[ConversationMemory] Erro ao construir contexto hierÃ¡rquico', {
        error: error.message,
        conversationId,
        userId
      });

      // Fallback: retornar apenas short-term em caso de erro
      return {
        shortTerm: await this.getShortTermMemory(conversationId),
        mediumTerm: { messages: [], summary: null },
        longTerm: { relevantContext: [], index: null },
        stats: { error: error.message }
      };
    }
  }

  /**
   * MEMÃ“RIA DE CURTO PRAZO: Ãšltimas 100 mensagens (contexto completo)
   */
  async getShortTermMemory(conversationId) {
    try {
      // Para novas conversas (conversationId null), nÃ£o hÃ¡ histÃ³rico curto prazo ainda
      if (!conversationId) {
        return {
          messages: [],
          count: 0,
          estimatedTokens: 0,
          type: 'full_context'
        };
      }

      const messages = await ConversationRepository.getConversationMessages(conversationId, {
        limit: MEMORY_LIMITS.shortTerm.maxMessages,
        offset: 0
      });

      // Mensagens jÃ¡ vÃªm em ordem cronolÃ³gica (ASC)
      const sortedMessages = messages;

      // Calcular tokens estimados
      const totalTokens = this.estimateTokens(sortedMessages);

      logger.debug('[ConversationMemory] Short-term memory loaded', {
        conversationId,
        messageCount: sortedMessages.length,
        estimatedTokens: totalTokens
      });

      return {
        messages: sortedMessages,
        count: sortedMessages.length,
        estimatedTokens: totalTokens,
        type: 'full_context'
      };
    } catch (error) {
      logger.error('[ConversationMemory] Erro ao carregar short-term memory', {
        error: error.message,
        conversationId
      });
      return { messages: [], count: 0, estimatedTokens: 0, type: 'full_context' };
    }
  }

  /**
   * MEMÃ“RIA DE MÃ‰DIO PRAZO: Resumos das mensagens 100-500
   */
  async getMediumTermMemory(conversationId) {
    try {
      // Para novas conversas (conversationId null), nÃ£o hÃ¡ histÃ³rico mÃ©dio prazo ainda
      if (!conversationId) {
        return { messages: [], summary: null, count: 0, estimatedTokens: 0, type: 'compressed_summary' };
      }

      // Verificar cache primeiro
      const cacheKey = `summary_${conversationId}`;
      if (this.summaryCache.has(cacheKey)) {
        logger.debug('[ConversationMemory] Using cached medium-term summary');
        return this.summaryCache.get(cacheKey);
      }

      // Buscar mensagens antigas (offset 100)
      const oldMessages = await ConversationRepository.getConversationMessages(conversationId, {
        limit: MEMORY_LIMITS.mediumTerm.maxMessages,
        offset: MEMORY_LIMITS.shortTerm.maxMessages
      });

      if (oldMessages.length === 0) {
        return { messages: [], summary: null, estimatedTokens: 0 };
      }

      // Mensagens jÃ¡ vÃªm em ordem cronolÃ³gica
      const sortedOldMessages = oldMessages;

      // Gerar resumo compactado
      const summary = await this.generateCompressedSummary(sortedOldMessages, conversationId);

      const result = {
        messages: sortedOldMessages,
        summary,
        count: sortedOldMessages.length,
        estimatedTokens: this.estimateTokens([{ content: summary }]),
        type: 'compressed_summary'
      };

      // Cachear resultado (TTL: 5 minutos)
      this.summaryCache.set(cacheKey, result);
      setTimeout(() => this.summaryCache.delete(cacheKey), 5 * 60 * 1000);

      logger.info('[ConversationMemory] Medium-term memory summarized', {
        conversationId,
        originalMessages: sortedOldMessages.length,
        summaryTokens: result.estimatedTokens
      });

      return result;
    } catch (error) {
      logger.error('[ConversationMemory] Erro ao carregar medium-term memory', {
        error: error.message,
        conversationId
      });
      return { messages: [], summary: null, estimatedTokens: 0 };
    }
  }

  /**
   * MEMÃ“RIA DE LONGO PRAZO: Busca semÃ¢ntica em conversas anteriores
   */
  async getLongTermMemory(userId, currentMessage) {
    try {
      if (!userId || userId === 'anonymous') {
        // UsuÃ¡rios anÃ´nimos nÃ£o tÃªm acesso a memÃ³ria de longo prazo
        return { relevantContext: [], index: null };
      }

      // Buscar conversas anteriores do usuÃ¡rio
      const previousConversations = await ConversationRepository.listUserConversations(userId, {
        limit: MEMORY_LIMITS.longTerm.maxConversations,
        includeArchived: false
      });

      if (previousConversations.length === 0) {
        return { relevantContext: [], index: null };
      }

      // Encontrar conversas relevantes baseado na mensagem atual
      const relevantContext = await this.findRelevantContext(
        previousConversations,
        currentMessage,
        userId
      );

      logger.info('[ConversationMemory] Long-term memory retrieved', {
        userId,
        totalConversations: previousConversations.length,
        relevantConversations: relevantContext.length
      });

      return {
        relevantContext,
        index: previousConversations.length,
        type: 'semantic_index'
      };
    } catch (error) {
      logger.error('[ConversationMemory] Erro ao carregar long-term memory', {
        error: error.message,
        userId
      });
      return { relevantContext: [], index: null };
    }
  }

  /**
   * Gerar resumo compactado de mensagens usando Claude
   */
  async generateCompressedSummary(messages, conversationId) {
    try {
      // Concatenar mensagens
      const conversationText = messages
        .map(m => `${m.role}: ${m.content}`)
        .join('\n\n');

      // Prompt para resumir preservando informaÃ§Ãµes crÃ­ticas
      const summaryPrompt = `VocÃª Ã© um assistente especializado em resumir conversas jurÃ­dicas preservando TODAS as informaÃ§Ãµes crÃ­ticas.

Analise a conversa abaixo e crie um resumo ULTRA-COMPACTO (mÃ¡ximo 20% do tamanho original) que preserve:
1. Todos os nÃºmeros de processo mencionados
2. Todas as datas importantes
3. Todos os nomes de partes, advogados, juÃ­zes
4. Todos os pedidos e decisÃµes
5. Todas as conclusÃµes jurÃ­dicas
6. Contexto essencial para continuidade

CONVERSA:
${conversationText}

RESUMO COMPACTO (mÃ¡ximo ${Math.round(conversationText.length * 0.2)} caracteres):`;

      let summary = '';

      // Usar streaming para gerar resumo
      await conversarStream(summaryPrompt, (chunk) => {
        summary += chunk;
      }, {
        modelo: 'anthropic.claude-haiku-4-5-20251001-v1:0', // Usar Haiku (rÃ¡pido e barato)
        maxTokens: Math.round(this.estimateTokens(messages) * MEMORY_LIMITS.mediumTerm.compressionRatio),
        systemPrompt: 'VocÃª Ã© um resumidor ultra-eficiente. Seja extremamente conciso preservando todas informaÃ§Ãµes crÃ­ticas.',
        enableTools: false
      });

      return summary.trim();
    } catch (error) {
      logger.error('[ConversationMemory] Erro ao gerar resumo compactado', {
        error: error.message,
        conversationId
      });

      // Fallback: resumo simples por truncamento
      const conversationText = messages
        .map(m => `${m.role}: ${m.content.substring(0, 200)}`)
        .join('\n');
      return conversationText.substring(0, 1000) + '...';
    }
  }

  /**
   * Encontrar contexto relevante de conversas anteriores usando BUSCA SEMÃ‚NTICA REAL
   */
  async findRelevantContext(previousConversations, currentMessage, userId) {
    try {
      // ESTRATÃ‰GIA HÃBRIDA: Busca semÃ¢ntica (vetorial) + Keywords (fallback)

      // 1. BUSCA SEMÃ‚NTICA VETORIAL (Primary)
      try {
        logger.debug('[ConversationMemory] Iniciando busca semÃ¢ntica vetorial...');

        // Preparar conversas com mensagens para embedding
        const conversationsWithMessages = await Promise.all(
          previousConversations.slice(0, 20).map(async (conv) => {
            const messages = await ConversationRepository.getConversationMessages(conv.id, {
              limit: 10,
              offset: 0
            });
            return {
              ...conv,
              messages
            };
          })
        );

        // Buscar conversas semanticamente similares
        const similarConversations = await semanticSearchService.searchSimilarConversations(
          currentMessage,
          conversationsWithMessages,
          {
            threshold: 0.60,  // 60% de similaridade mÃ­nima (reduzido de 65% para melhor recall)
            topK: 3,          // MÃ¡ximo 3 conversas
            includeMessages: true
          }
        );

        if (similarConversations.length > 0) {
          // Sucesso! Encontrou conversas similares por busca vetorial
          const relevantConvs = await Promise.all(
            similarConversations.map(async (conv) => {
              // Buscar mensagens mais similares dentro da conversa
              const messages = await ConversationRepository.getConversationMessages(conv.id, {
                limit: 20,
                offset: 0
              });

              const similarMessages = await semanticSearchService.searchSimilarMessages(
                currentMessage,
                messages,
                {
                  threshold: 0.65,  // 65% para mensagens individuais (reduzido de 70% para melhor recall)
                  topK: 3
                }
              );

              return {
                conversationId: conv.id,
                title: conv.title,
                date: conv.created_at,
                similarity: conv.similarity,
                similarityPercent: conv.similarityPercent,
                relevantMessages: similarMessages,
                searchType: 'semantic_vector'
              };
            })
          );

          logger.info('[ConversationMemory] Busca semÃ¢ntica vetorial bem-sucedida', {
            conversationsFound: relevantConvs.length,
            avgSimilarity: Math.round(
              relevantConvs.reduce((sum, c) => sum + c.similarity, 0) / relevantConvs.length * 100
            )
          });

          return relevantConvs;
        }
      } catch (semanticError) {
        logger.warn('[ConversationMemory] Busca semÃ¢ntica falhou, usando fallback por keywords', {
          error: semanticError.message
        });
        // Continuar para fallback por keywords
      }

      // 2. FALLBACK: BUSCA POR KEYWORDS (Secondary)
      logger.debug('[ConversationMemory] Usando busca por keywords (fallback)...');

      const keywords = this.extractKeywords(currentMessage);
      const relevantConvs = [];

      for (const conv of previousConversations.slice(0, 10)) {
        const messages = await ConversationRepository.getConversationMessages(conv.id, {
          limit: 20,
          offset: 0
        });

        // Verificar se alguma mensagem contÃ©m keywords
        const hasRelevantContent = messages.some(msg =>
          keywords.some(keyword => msg.content.toLowerCase().includes(keyword.toLowerCase()))
        );

        if (hasRelevantContent) {
          relevantConvs.push({
            conversationId: conv.id,
            title: conv.title,
            date: conv.created_at,
            similarity: 0,
            similarityPercent: 0,
            relevantMessages: messages.filter(msg =>
              keywords.some(keyword => msg.content.toLowerCase().includes(keyword.toLowerCase()))
            ).slice(0, 3),
            searchType: 'keyword_fallback'
          });
        }

        if (relevantConvs.length >= 3) break;
      }

      if (relevantConvs.length > 0) {
        logger.info('[ConversationMemory] Busca por keywords retornou resultados', {
          conversationsFound: relevantConvs.length
        });
      }

      return relevantConvs;
    } catch (error) {
      logger.error('[ConversationMemory] Erro ao buscar contexto relevante', {
        error: error.message,
        userId
      });
      return [];
    }
  }

  /**
   * Extrair palavras-chave de uma mensagem
   */
  extractKeywords(message) {
    // Extrair nÃºmeros de processo
    const processos = message.match(/\d{7}-?\d{2}\.\d{4}\.\d{1}\.\d{2}\.\d{4}/g) || [];

    // Extrair nomes prÃ³prios (palavras com maiÃºscula inicial)
    const nomes = message.match(/\b[A-ZÃ€-Ãš][a-zÃ -Ãº]+(?:\s+[A-ZÃ€-Ãš][a-zÃ -Ãº]+)*\b/g) || [];

    // Extrair palavras jurÃ­dicas importantes
    const palavrasJuridicas = message.toLowerCase().match(/\b(petiÃ§Ã£o|recurso|apelaÃ§Ã£o|agravo|sentenÃ§a|acÃ³rdÃ£o|processo|aÃ§Ã£o|autor|rÃ©u|advogado|juiz|tribunal|decisÃ£o|liminar|tutela|contestaÃ§Ã£o|rÃ©plica|embargos|habeas corpus|mandado)\b/g) || [];

    // Combinar e remover duplicatas
    const keywords = [...new Set([...processos, ...nomes, ...palavrasJuridicas])];

    return keywords.slice(0, 10); // MÃ¡ximo 10 keywords
  }

  /**
   * Estimar tokens de mensagens
   */
  estimateTokens(messages) {
    if (!messages || messages.length === 0) return 0;

    // Estimativa: ~4 caracteres = 1 token
    const totalChars = messages.reduce((sum, msg) => {
      const content = typeof msg === 'string' ? msg : (msg.content || '');
      return sum + content.length;
    }, 0);

    return Math.ceil(totalChars / 4);
  }

  /**
   * Calcular estatÃ­sticas de memÃ³ria
   */
  calculateMemoryStats(shortTerm, mediumTerm, longTerm) {
    return {
      shortTerm: {
        messages: shortTerm.count || 0,
        tokens: shortTerm.estimatedTokens || 0,
        type: shortTerm.type
      },
      mediumTerm: {
        messages: mediumTerm.count || 0,
        tokens: mediumTerm.estimatedTokens || 0,
        type: mediumTerm.type,
        compressed: !!mediumTerm.summary
      },
      longTerm: {
        conversations: longTerm.index || 0,
        relevantItems: longTerm.relevantContext?.length || 0,
        type: longTerm.type
      },
      totalTokens: (shortTerm.estimatedTokens || 0) + (mediumTerm.estimatedTokens || 0),
      limits: {
        shortTerm: MEMORY_LIMITS.shortTerm,
        mediumTerm: MEMORY_LIMITS.mediumTerm,
        longTerm: MEMORY_LIMITS.longTerm
      }
    };
  }

  /**
   * Formatar contexto hierÃ¡rquico para o prompt
   */
  formatContextForPrompt(hierarchicalContext) {
    const parts = [];

    // 1. MemÃ³ria de longo prazo (se houver)
    if (hierarchicalContext.longTerm?.relevantContext?.length > 0) {
      parts.push('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
      parts.push('MEMÃ“RIA DE LONGO PRAZO - Contexto de Conversas Anteriores');
      parts.push('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');

      // âš ï¸ INSTRUÃ‡ÃƒO CRÃTICA: Dizer ao Claude para MENCIONAR EXPLICITAMENTE as conversas anteriores
      parts.push('ğŸ”” IMPORTANTE: As informaÃ§Ãµes abaixo sÃ£o de conversas anteriores do usuÃ¡rio.');
      parts.push('Quando essas informaÃ§Ãµes forem RELEVANTES para responder a pergunta atual:');
      parts.push('  â€¢ MENCIONE EXPLICITAMENTE que sÃ£o de conversas anteriores');
      parts.push('  â€¢ Use frases como: "Como discutimos anteriormente...", "Em nossa conversa anterior sobre...", "VocÃª jÃ¡ havia mencionado..."');
      parts.push('  â€¢ Isso demonstra continuidade e memÃ³ria de longo prazo ao usuÃ¡rio');
      parts.push('  â€¢ Se as informaÃ§Ãµes NÃƒO forem relevantes para a pergunta atual, ignore-as\n');

      hierarchicalContext.longTerm.relevantContext.forEach((conv, idx) => {
        // Incluir informaÃ§Ã£o de similaridade se disponÃ­vel
        const similarityInfo = conv.similarity > 0
          ? ` [Similaridade: ${conv.similarityPercent}% - Busca ${conv.searchType === 'semantic_vector' ? 'SEMÃ‚NTICA VETORIAL' : 'por Keywords'}]`
          : '';

        parts.push(`[CONVERSA ANTERIOR ${idx + 1}] ${conv.title || 'Sem tÃ­tulo'} (${conv.date})${similarityInfo}`);

        conv.relevantMessages?.forEach(msg => {
          const msgSimilarity = msg.similarity > 0 ? ` [${msg.similarityPercent}%]` : '';
          const preview = msg.content.length > 300 ? msg.content.substring(0, 300) + '...' : msg.content;
          parts.push(`  ${msg.role}${msgSimilarity}: ${preview}`);
        });
        parts.push('');
      });

      parts.push('');
    }

    // 2. MemÃ³ria de mÃ©dio prazo (resumo)
    if (hierarchicalContext.mediumTerm?.summary) {
      parts.push('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
      parts.push(`MEMÃ“RIA DE MÃ‰DIO PRAZO - Resumo das Mensagens Antigas (${hierarchicalContext.mediumTerm.count} mensagens)`);
      parts.push('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');
      parts.push(hierarchicalContext.mediumTerm.summary);
      parts.push('\n');
    }

    // 3. MemÃ³ria de curto prazo nÃ£o precisa ser formatada aqui
    // SerÃ¡ incluÃ­da como histÃ³rico normal na chamada do Bedrock

    return parts.join('\n');
  }

  /**
   * Limpar caches (chamado periodicamente)
   */
  clearCaches() {
    this.summaryCache.clear();
    this.indexCache.clear();
    logger.info('[ConversationMemory] Caches cleared');
  }
}

// Exportar instÃ¢ncia singleton
export default new ConversationMemoryService();
