# ğŸ§ª RELATÃ“RIO COMPLETO - TESTE DE MODELOS AWS BEDROCK

**Data:** 17/12/2025 01:07 AM
**RegiÃ£o:** us-east-1
**Modelos Testados:** 29
**Taxa de Sucesso:** 75.9% (22/29)

---

## âœ… RESUMO EXECUTIVO

### EstatÃ­sticas Gerais
- âœ… **22 modelos funcionando** (75.9%)
- âŒ **7 modelos falharam** (24.1%)
- âš¡ **LatÃªncia mÃ©dia:** 919ms
- ğŸ† **Mais rÃ¡pido:** Cohere Command R (639ms)
- ğŸ¢ **Mais lento:** Claude Sonnet 4.5 (2192ms)

### Principais Descobertas
1. **6 modelos premium** requerem Inference Profile (nÃ£o suportam on-demand direto)
2. **1 modelo** atingiu rate limit durante teste (Claude 3 Opus)
3. **Meta Llama** e **Cohere** sÃ£o os mais rÃ¡pidos
4. **Claude Sonnet 4.5** (padrÃ£o atual) Ã© o mais lento, mas funciona

---

## âœ… MODELOS QUE FUNCIONAM (22)

### ğŸ† TOP 10 MAIS RÃPIDOS

| # | Modelo | LatÃªncia | Uso Recomendado |
|---|--------|----------|-----------------|
| 1 | **Cohere Command R** | 639ms | RAG, busca semÃ¢ntica |
| 2 | **Meta Llama 3.3 70B** | 652ms | AnÃ¡lises gerais |
| 3 | **Meta Llama 4 Maverick 17B** | 657ms | Tarefas rÃ¡pidas |
| 4 | **Anthropic Claude 3 Haiku** | 686ms | Resumos rÃ¡pidos |
| 5 | **Cohere Command R+** | 687ms | RAG avanÃ§ado |
| 6 | **Mistral Ministral 3 14B** | 715ms | Tarefas mÃ©dias |
| 7 | **Meta Llama 3.1 8B** | 733ms | Ultra rÃ¡pido |
| 8 | **Mistral Ministral 3 8B** | 734ms | Tarefas simples |
| 9 | **Anthropic Claude 3 Sonnet** | 748ms | EquilÃ­brio |
| 10 | **Meta Llama 3.2 11B** | 802ms | Respostas rÃ¡pidas |

### ğŸ“‹ LISTA COMPLETA (ordenada por velocidade)

#### Amazon Nova (4/5 funcionando)
```
âœ… amazon.nova-micro-v1:0          821ms  - Ultra Fast
âœ… amazon.nova-lite-v1:0           857ms  - Fast
âœ… amazon.nova-pro-v1:0            899ms  - Balanced
âœ… amazon.titan-text-express-v1    1121ms - Titan
âŒ amazon.nova-premier-v1:0               - Requer Inference Profile
```

#### Anthropic Claude (7/10 funcionando)
```
âœ… anthropic.claude-3-haiku-20240307-v1:0           686ms  - Mais rÃ¡pido
âœ… anthropic.claude-3-sonnet-20240229-v1:0          748ms  - Veloz
âœ… anthropic.claude-3-5-haiku-20241022-v1:0         1063ms - Haiku 3.5
âœ… anthropic.claude-3-5-sonnet-20241022-v2:0        1083ms - Sonnet 3.5
âœ… anthropic.claude-sonnet-4-20250514-v1:0          1451ms - Sonnet 4
âœ… anthropic.claude-sonnet-4-5-20250929-v1:0        2192ms - PadrÃ£o atual
âŒ anthropic.claude-3-opus-20240229-v1:0                   - Rate limit (429)
âŒ anthropic.claude-haiku-4-5-20251001-v1:0                - Requer Inference Profile
âŒ anthropic.claude-opus-4-20250514-v1:0                   - Requer Inference Profile
âŒ anthropic.claude-opus-4-5-20251101-v1:0                 - Requer Inference Profile
```

#### Meta Llama (7/7 funcionando - 100%!)
```
âœ… meta.llama3-3-70b-instruct-v1:0            652ms  - CAMPEÃƒO Meta
âœ… meta.llama4-maverick-17b-instruct-v1:0     657ms  - Llama 4 rÃ¡pido
âœ… meta.llama3-1-8b-instruct-v1:0             733ms  - Menor, mais rÃ¡pido
âœ… meta.llama3-2-11b-instruct-v1:0            802ms  - MÃ©dio
âœ… meta.llama4-scout-17b-instruct-v1:0        830ms  - Llama 4
âœ… meta.llama3-1-70b-instruct-v1:0            944ms  - Grande
âœ… meta.llama3-2-90b-instruct-v1:0            1000ms - Maior
```

#### Mistral AI (3/4 funcionando)
```
âœ… mistral.ministral-3-14b-instruct          715ms  - RÃ¡pido
âœ… mistral.ministral-3-8b-instruct           734ms  - Ultra rÃ¡pido
âœ… mistral.mistral-large-3-675b-instruct     900ms  - Grande
âŒ mistral.pixtral-large-2502-v1:0                  - Requer Inference Profile
```

#### Cohere (2/2 funcionando - 100%!)
```
âœ… cohere.command-r-v1:0                     639ms  - CAMPEÃƒO GERAL
âœ… cohere.command-r-plus-v1:0                687ms  - RAG otimizado
```

#### DeepSeek (0/1)
```
âŒ deepseek.r1-v1:0  - Requer Inference Profile
```

---

## âŒ MODELOS QUE FALHARAM (7)

### Problema: Requerem Inference Profile (6 modelos)

Estes modelos **existem** mas nÃ£o suportam invocaÃ§Ã£o on-demand direta. Ã‰ necessÃ¡rio usar **Inference Profile** com prefixo regional:

```
âŒ amazon.nova-premier-v1:0
   Erro: "isn't supported with on-demand throughput"
   SoluÃ§Ã£o: Usar us.amazon.nova-premier-v1:0

âŒ anthropic.claude-opus-4-5-20251101-v1:0
   Erro: "isn't supported with on-demand throughput"
   SoluÃ§Ã£o: Usar us.anthropic.claude-opus-4-5-20251101-v1:0

âŒ anthropic.claude-opus-4-20250514-v1:0
   Erro: "isn't supported with on-demand throughput"
   SoluÃ§Ã£o: Usar us.anthropic.claude-opus-4-20250514-v1:0

âŒ anthropic.claude-haiku-4-5-20251001-v1:0
   Erro: "isn't supported with on-demand throughput"
   SoluÃ§Ã£o: Usar us.anthropic.claude-haiku-4-5-20251001-v1:0

âŒ mistral.pixtral-large-2502-v1:0
   Erro: "isn't supported with on-demand throughput"
   SoluÃ§Ã£o: Usar us.mistral.pixtral-large-2502-v1:0

âŒ deepseek.r1-v1:0
   Erro: "isn't supported with on-demand throughput"
   SoluÃ§Ã£o: Usar us.deepseek.r1-v1:0
```

### Problema: Rate Limit (1 modelo)

```
âŒ anthropic.claude-3-opus-20240229-v1:0
   Erro: "Too many tokens, please wait before trying again"
   Motivo: Atingiu rate limit durante teste sequencial
   SoluÃ§Ã£o: Aguardar ou usar inference profile us.anthropic.claude-3-opus-20240229-v1:0
```

---

## ğŸ¯ RECOMENDAÃ‡Ã•ES POR CASO DE USO

### 1ï¸âƒ£ AnÃ¡lises JurÃ­dicas Complexas (Qualidade MÃ¡xima)
**Recomendado:**
```
1Âº anthropic.claude-sonnet-4-5-20250929-v1:0  (padrÃ£o atual, funciona)
2Âº anthropic.claude-sonnet-4-20250514-v1:0    (alternativa rÃ¡pida)
3Âº anthropic.claude-3-5-sonnet-20241022-v2:0  (backup)
```

### 2ï¸âƒ£ Respostas RÃ¡pidas (Velocidade)
**Recomendado:**
```
1Âº cohere.command-r-v1:0                 (639ms - CAMPEÃƒO)
2Âº meta.llama3-3-70b-instruct-v1:0       (652ms)
3Âº anthropic.claude-3-haiku-20240307-v1:0 (686ms)
```

### 3ï¸âƒ£ Pesquisa RAG / JurisprudÃªncia
**Recomendado:**
```
1Âº cohere.command-r-plus-v1:0            (687ms - otimizado RAG)
2Âº cohere.command-r-v1:0                 (639ms)
3Âº meta.llama3-3-70b-instruct-v1:0       (652ms)
```

### 4ï¸âƒ£ Resumos de Documentos (Volume)
**Recomendado:**
```
1Âº meta.llama3-1-8b-instruct-v1:0        (733ms - econÃ´mico)
2Âº mistral.ministral-3-8b-instruct       (734ms)
3Âº amazon.nova-micro-v1:0                (821ms)
```

### 5ï¸âƒ£ AnÃ¡lise de Processos Grandes (200k+ tokens)
**Recomendado:**
```
1Âº anthropic.claude-sonnet-4-5-20250929-v1:0  (200k contexto)
2Âº anthropic.claude-3-5-sonnet-20241022-v2:0  (200k contexto)
3Âº meta.llama3-2-90b-instruct-v1:0            (128k contexto)
```

---

## ğŸ”§ AÃ‡Ã•ES NECESSÃRIAS

### Curto Prazo (Implementar Agora)

1. **Adicionar Inference Profiles faltantes:**
```javascript
// Adicionar em src/modules/bedrock.js:

export const INFERENCE_PROFILES = {
  // ... existentes ...

  // NOVOS (modelos premium que falharam):
  'amazon.nova-premier-v1:0': 'us.amazon.nova-premier-v1:0',
  'anthropic.claude-opus-4-5-20251101-v1:0': 'us.anthropic.claude-opus-4-5-20251101-v1:0',
  'anthropic.claude-opus-4-20250514-v1:0': 'us.anthropic.claude-opus-4-20250514-v1:0',
  'anthropic.claude-haiku-4-5-20251001-v1:0': 'us.anthropic.claude-haiku-4-5-20251001-v1:0',
  'mistral.pixtral-large-2502-v1:0': 'us.mistral.pixtral-large-2502-v1:0',
  'deepseek.r1-v1:0': 'us.deepseek.r1-v1:0'
};
```

2. **Atualizar modelo padrÃ£o para mais rÃ¡pido (opcional):**
```javascript
// Se quiser priorizar velocidade sobre qualidade mÃ¡xima:
defaultModel: 'anthropic.claude-3-5-sonnet-20241022-v2:0'  // 1083ms vs 2192ms

// OU manter atual para mÃ¡xima qualidade:
defaultModel: 'anthropic.claude-sonnet-4-5-20250929-v1:0'  // 2192ms
```

3. **Remover modelos invÃ¡lidos da lista:**
   - Todos estÃ£o vÃ¡lidos! Apenas precisam de inference profiles

### MÃ©dio Prazo (OtimizaÃ§Ãµes)

4. **Implementar seleÃ§Ã£o automÃ¡tica de modelo por tipo de tarefa:**
```javascript
// Resumo rÃ¡pido â†’ Cohere Command R (639ms)
// AnÃ¡lise complexa â†’ Claude Sonnet 4.5 (2192ms)
// RAG/Busca â†’ Cohere Command R+ (687ms)
// Volume grande â†’ Llama 3.1 8B (733ms)
```

5. **Testar modelos premium apÃ³s adicionar inference profiles:**
```bash
node test-all-models.js  # Rodar novamente apÃ³s correÃ§Ãµes
```

---

## ğŸ“Š ANÃLISE ESTATÃSTICA

### DistribuiÃ§Ã£o de LatÃªncia

```
< 700ms:  6 modelos (27%) - ULTRA RÃPIDOS
700-900ms: 10 modelos (45%) - RÃPIDOS
900-1200ms: 4 modelos (18%) - MÃ‰DIOS
> 1200ms: 2 modelos (9%) - LENTOS
```

### Performance por Provedor

| Provedor | Funcionando | Taxa Sucesso | LatÃªncia MÃ©dia |
|----------|-------------|--------------|----------------|
| **Cohere** | 2/2 | 100% | 663ms â­ |
| **Meta Llama** | 7/7 | 100% | 804ms â­ |
| **Amazon** | 4/5 | 80% | 924ms |
| **Mistral** | 3/4 | 75% | 783ms |
| **Anthropic** | 6/10 | 60% | 1176ms |
| **DeepSeek** | 0/1 | 0% | N/A |

### CampeÃµes por Categoria

```
ğŸ† Velocidade Geral:     Cohere Command R (639ms)
ğŸ† Melhor Meta Llama:    Llama 3.3 70B (652ms)
ğŸ† Melhor Claude:        Claude 3 Haiku (686ms)
ğŸ† Melhor Amazon:        Nova Micro (821ms)
ğŸ† Melhor Mistral:       Ministral 3 14B (715ms)
ğŸ† Melhor para RAG:      Cohere Command R+ (687ms)
ğŸ† MÃ¡xima Qualidade:     Claude Sonnet 4.5 (2192ms)
```

---

## ğŸ’¡ CONCLUSÃ•ES E PRÃ“XIMOS PASSOS

### âœ… O Que Funciona Bem
1. **22 modelos ativos** - Ã³tima variedade de opÃ§Ãµes
2. **Meta Llama** - 100% funcionando, excelente velocidade
3. **Cohere** - 100% funcionando, CAMPEÃƒO em velocidade
4. **Claude Sonnet 4.5** - funciona (padrÃ£o atual OK)

### âš ï¸ Problemas Identificados
1. **6 modelos premium** precisam de inference profiles
2. **Rate limit** em Claude 3 Opus (temporÃ¡rio)
3. **LatÃªncia alta** no Claude Sonnet 4.5 (2x mais lento que alternativas)

### ğŸš€ AÃ§Ãµes Imediatas
1. âœ… **Adicionar inference profiles** para os 6 modelos premium
2. âš ï¸ **Considerar trocar padrÃ£o** para Claude 3.5 Sonnet (2x mais rÃ¡pido)
3. âœ… **Implementar seleÃ§Ã£o automÃ¡tica** por tipo de tarefa
4. âœ… **Re-testar apÃ³s correÃ§Ãµes**

### ğŸ“ˆ BenefÃ­cios Esperados
- **+6 modelos premium** disponÃ­veis (Opus 4.5, Haiku 4.5, DeepSeek R1, etc)
- **ReduÃ§Ã£o 50% latÃªncia** se trocar padrÃ£o (2192ms â†’ 1083ms)
- **Melhor custo/benefÃ­cio** com seleÃ§Ã£o automÃ¡tica

---

**RelatÃ³rio gerado:** 17/12/2025 01:07 AM
**Arquivo JSON:** test-models-report.json
**PrÃ³ximo teste:** ApÃ³s implementar inference profiles
