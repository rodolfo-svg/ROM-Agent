# ‚ö° Plano de Otimiza√ß√£o de Performance - ROM Agent

**Baseline Atual**: 6.2 segundos por resposta
**Meta**: < 3 segundos por resposta
**Ganho esperado**: ~50% mais r√°pido

---

## üìä An√°lise Atual

### ‚úÖ O que j√° est√° otimizado:
- AWS Bedrock nativo (sem overhead de Anthropic API)
- Compression Gzip/Brotli ativado
- Rate limiting implementado
- Cache em mem√≥ria (30min TTL)
- Apenas 3 processos Node rodando

### ‚ö†Ô∏è Gargalos identificados:
1. **Sem streaming de respostas** (esperando resposta completa)
2. **Modelo pesado** (Nova Pro vs Nova Lite)
3. **Hist√≥rico n√£o limitado** (cresce infinitamente)
4. **Sem cache de respostas similares**
5. **Conex√µes HTTP/1.1** (sem keep-alive otimizado)
6. **Parser JSON s√≠ncrono** (bloqueia event loop)
7. **Sem pr√©-aquecimento de conex√µes**
8. **Queries sequenciais** (poderia ser paralelo)

---

## üöÄ Otimiza√ß√µes Propostas (Ordem de Impacto)

### 1. **STREAMING DE RESPOSTAS** üåä
**Impacto**: -60% tempo percebido pelo usu√°rio
**Implementa√ß√£o**: J√° existe c√≥digo, basta usar!

#### Mudan√ßa:
```javascript
// ANTES (atual):
const resultado = await agent.enviar(message);
// Usu√°rio espera 6s para ver QUALQUER coisa

// DEPOIS (streaming):
app.post('/api/chat-stream', async (req, res) => {
  // Usu√°rio come√ßa a ver resposta em < 1s
  await conversarStream(message, (chunk) => {
    res.write(`data: ${JSON.stringify({ chunk })}\\n\\n`);
  });
});
```

#### Arquivo: `src/server-enhanced.js:389-453`
**Status**: ‚úÖ J√° implementado, s√≥ precisa ser o m√©todo padr√£o

---

### 2. **MODELO MAIS R√ÅPIDO** ‚ö°
**Impacto**: -40% tempo de processamento
**Custo**: Qualidade ligeiramente menor (aceit√°vel para chat)

#### Mudan√ßa:
```javascript
// ANTES:
modelo: 'amazon.nova-pro-v1:0'  // Mais lento, mais inteligente
// Tempo: ~6s

// DEPOIS:
modelo: 'amazon.nova-lite-v1:0' // Mais r√°pido, ainda bom
// Tempo: ~3.5s

// OU (ultra r√°pido):
modelo: 'amazon.nova-micro-v1:0' // R√°pido, respostas curtas
// Tempo: ~2s
```

#### Arquivo: `src/server-enhanced.js:212`

**Recomenda√ß√£o**:
- Usar **Nova Lite** como padr√£o
- Permitir usu√°rio escolher modelo no frontend
- Auto-switch: perguntas simples ‚Üí Lite, complexas ‚Üí Pro

---

### 3. **CACHE DE RESPOSTAS SIMILARES** üíæ
**Impacto**: -90% em perguntas repetidas
**Implementa√ß√£o**: Redis ou Map() em mem√≥ria

#### C√≥digo:
```javascript
// lib/response-cache.js
import crypto from 'crypto';

class ResponseCache {
  constructor() {
    this.cache = new Map();
    this.ttl = 3600000; // 1 hora
  }

  hashQuery(query) {
    return crypto.createHash('md5').update(query.toLowerCase()).digest('hex');
  }

  get(query) {
    const hash = this.hashQuery(query);
    const cached = this.cache.get(hash);

    if (cached && Date.now() - cached.timestamp < this.ttl) {
      console.log(`‚úÖ Cache HIT: ${query.substring(0, 50)}`);
      return cached.response;
    }

    this.cache.delete(hash);
    return null;
  }

  set(query, response) {
    const hash = this.hashQuery(query);
    this.cache.set(hash, {
      response,
      timestamp: Date.now()
    });
  }
}

export default new ResponseCache();
```

#### Uso no servidor:
```javascript
import responseCache from '../lib/response-cache.js';

app.post('/api/chat', async (req, res) => {
  // Verificar cache primeiro
  const cached = responseCache.get(req.body.message);
  if (cached) {
    return res.json({ response: cached, cached: true });
  }

  // Processar normalmente
  const resultado = await agent.enviar(message);

  // Salvar no cache
  responseCache.set(message, resultado.resposta);

  res.json({ response: resultado.resposta });
});
```

**Tempo**: < 50ms para cache hits!

---

### 4. **LIMITAR HIST√ìRICO** üìú
**Impacto**: -10% tempo de processamento
**Raz√£o**: Menos tokens enviados ao modelo

#### Mudan√ßa:
```javascript
// ANTES:
const history = getHistory(req.session.id);
// Hist√≥rico cresce infinitamente

// DEPOIS:
const history = getHistory(req.session.id).slice(-10); // √öltimas 10 msgs
// Ou: slice(-20) para contexto maior
```

#### Arquivo: `src/server-enhanced.js:241`

**C√°lculo**:
- 10 mensagens = ~2000 tokens
- 100 mensagens = ~20000 tokens
- Diferen√ßa: -90% tokens de entrada!

---

### 5. **PARALELIZA√á√ÉO DE OPERA√á√ïES** üîÄ
**Impacto**: -30% tempo em opera√ß√µes m√∫ltiplas
**Uso**: Pesquisa de jurisprud√™ncia, an√°lises

#### C√≥digo:
```javascript
// ANTES (sequencial):
const legislacao = await buscarLegislacao(tema);
const jurisprudencia = await buscarJurisprudencia(tema);
const doutrina = await buscarDoutrina(tema);
// Tempo total: 15s

// DEPOIS (paralelo):
const [legislacao, jurisprudencia, doutrina] = await Promise.all([
  buscarLegislacao(tema),
  buscarJurisprudencia(tema),
  buscarDoutrina(tema)
]);
// Tempo total: 5s (70% mais r√°pido!)
```

---

### 6. **HTTP/2 + KEEP-ALIVE** üîå
**Impacto**: -10% tempo de conex√£o
**Implementa√ß√£o**: Configurar Express/Node

#### C√≥digo:
```javascript
// src/server-enhanced.js
import http2 from 'http2';
import fs from 'fs';

// Criar servidor HTTP/2 (requer HTTPS)
const options = {
  key: fs.readFileSync('ssl/key.pem'),
  cert: fs.readFileSync('ssl/cert.pem'),
  allowHTTP1: true // Fallback para HTTP/1.1
};

const server = http2.createSecureServer(options, app);
server.listen(3000);
```

**Alternativa** (sem SSL, dev):
```javascript
// Melhorar keep-alive HTTP/1.1
app.use((req, res, next) => {
  res.setHeader('Connection', 'keep-alive');
  res.setHeader('Keep-Alive', 'timeout=5, max=100');
  next();
});
```

---

### 7. **PR√â-AQUECIMENTO DE CONEX√ïES** üî•
**Impacto**: -15% cold start
**Status**: ‚úÖ J√° implementado (linha 3875-3900)

#### Melhorias:
```javascript
// ANTES:
await conversar('ping', { modelo, maxTokens: 10 });
// Aguarda resposta completa

// DEPOIS (mais r√°pido):
const warmup = conversar('ping', { modelo, maxTokens: 5 });
// N√£o aguarda, faz em background
setTimeout(() => warmup, 0);
```

---

### 8. **PARSER JSON ASS√çNCRONO** üìù
**Impacto**: -5% em payloads grandes
**Implementa√ß√£o**: Usar stream parser

#### C√≥digo:
```javascript
import { JSONParser } from '@streamparser/json';

app.use(express.json({
  limit: '50mb',
  verify: (req, res, buf) => {
    // Parse ass√≠ncrono para payloads > 1MB
    if (buf.length > 1024 * 1024) {
      const parser = new JSONParser();
      parser.write(buf);
      req.bodyParsed = parser.value;
    }
  }
}));
```

---

## üéØ Implementa√ß√£o Recomendada (Prioridade)

### **FASE 1 - Ganho R√°pido** (30 min)
1. ‚úÖ Trocar para modelo Nova Lite (1 linha)
2. ‚úÖ Limitar hist√≥rico a 10 mensagens (1 linha)
3. ‚úÖ Usar streaming como padr√£o (mudar rota)

**Ganho esperado**: 6.2s ‚Üí **3.5s** (-43%)

### **FASE 2 - Otimiza√ß√£o Avan√ßada** (2h)
4. ‚úÖ Implementar cache de respostas
5. ‚úÖ Paralelizar opera√ß√µes DB/API
6. ‚úÖ HTTP/2 ou Keep-Alive melhorado

**Ganho esperado**: 3.5s ‚Üí **2.2s** (-37%)

### **FASE 3 - Polimento** (1h)
7. ‚úÖ Otimizar pr√©-aquecimento
8. ‚úÖ Parser JSON ass√≠ncrono

**Ganho esperado**: 2.2s ‚Üí **1.8s** (-18%)

---

## üìä Resultados Esperados

| Fase | Tempo | Ganho | Status |
|------|-------|-------|--------|
| Baseline | 6.2s | - | ‚úÖ Medido |
| Fase 1 | 3.5s | -43% | ‚è≥ Pendente |
| Fase 2 | 2.2s | -37% | ‚è≥ Pendente |
| Fase 3 | 1.8s | -18% | ‚è≥ Pendente |
| **TOTAL** | **1.8s** | **-71%** | üéØ Meta |

---

## üöÄ Come√ßar Agora - Comandos R√°pidos

### 1. Trocar para Nova Lite:
```bash
# Editar src/server-enhanced.js linha 212
sed -i '' 's/amazon.nova-pro-v1:0/amazon.nova-lite-v1:0/g' src/server-enhanced.js
```

### 2. Limitar hist√≥rico:
```bash
# Editar src/server-enhanced.js linha 241
# Adicionar .slice(-10) ap√≥s getHistory()
```

### 3. Testar velocidade:
```bash
time curl -X POST http://localhost:3000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message":"teste"}'
```

### 4. Usar streaming:
```bash
# Frontend: mudar de /api/chat para /api/chat-stream
# Backend: j√° implementado em linha 389-453
```

---

## üìù Checklist de Implementa√ß√£o

- [ ] Fase 1.1: Trocar modelo padr√£o para Nova Lite
- [ ] Fase 1.2: Limitar hist√≥rico a 10 mensagens
- [ ] Fase 1.3: Ativar streaming como padr√£o
- [ ] Fase 1.4: Testar e medir tempo
- [ ] Fase 2.1: Implementar cache de respostas
- [ ] Fase 2.2: Paralelizar opera√ß√µes
- [ ] Fase 2.3: Configurar keep-alive
- [ ] Fase 2.4: Testar e medir tempo
- [ ] Fase 3.1: Otimizar pr√©-aquecimento
- [ ] Fase 3.2: Parser JSON ass√≠ncrono
- [ ] Fase 3.3: Teste final e documentar

---

## üí° Dicas Extras

### Monitorar Performance:
```javascript
// Adicionar middleware de timing
app.use((req, res, next) => {
  req.startTime = Date.now();
  res.on('finish', () => {
    const duration = Date.now() - req.startTime;
    console.log(`${req.method} ${req.path} - ${duration}ms`);
  });
  next();
});
```

### Benchmarking:
```bash
# Testar 10 requisi√ß√µes
for i in {1..10}; do
  time curl -s -X POST http://localhost:3000/api/chat \
    -H "Content-Type: application/json" \
    -d "{\"message\":\"teste $i\"}"
done
```

### Profiling:
```bash
# Detectar gargalos
node --prof src/server-enhanced.js
# Ap√≥s teste, processar:
node --prof-process isolate-*.log > profile.txt
```

---

**√öltima atualiza√ß√£o**: 14/12/2025
**Autor**: Claude Code
**Vers√£o**: 1.0.0
