# ═══════════════════════════════════════════════════════════════
# ROM AGENT - CONFIGURAÇÃO RENDER.COM
# ═══════════════════════════════════════════════════════════════
# Serviço Web Principal - Interface Claude AI + API Bedrock
# Deploy automático via GitHub (main branch)
# ═══════════════════════════════════════════════════════════════

services:
  # ═══════════════════════════════════════════════════════════════
  # PRODUÇÃO - Branch main
  # ═══════════════════════════════════════════════════════════════
  - type: web
    name: rom-agent
    runtime: node
    plan: pro  # ✅ 4GB RAM - suficiente para merge de PDFs grandes
    branch: main

    # ═══ BUILD ═══
    buildCommand: bash scripts/build-production.sh

    # ═══ START ═══
    # CRÍTICO: Iniciar servidor IMEDIATAMENTE para evitar port scan timeout
    # Frontend já foi buildado no buildCommand
    # Migrations rodam assíncronamente após servidor abrir porta
    # MEMÓRIA: 3GB para Node.js (Pro 4GB total, deixa 1GB para sistema)
    startCommand: node --max-old-space-size=3072 scripts/ensure-frontend-build.js && node --max-old-space-size=3072 src/server-enhanced.js

    # ═══ VARIÁVEIS DE AMBIENTE ═══
    envVars:
      # Node.js
      - key: NODE_ENV
        value: production
      - key: NODE_VERSION
        value: 25.2.1

      # ═══ CONCORRÊNCIA - PRO PLAN ═══
      # Permite múltiplos workers para processar uploads simultâneos
      - key: WEB_CONCURRENCY
        value: 4  # 4 workers = suporta 4-8 uploads simultâneos processando

      # Porta (Render usa 10000)
      - key: PORT
        value: 10000

      # ✅ FORÇAR USO DO DISCO PERSISTENTE /var/data
      - key: RENDER
        value: "true"
      - key: UPLOAD_FOLDER
        value: /var/data/upload
      - key: EXTRACTED_FOLDER
        value: /var/data/extracted
      - key: PROCESSED_FOLDER
        value: /var/data/processed

      # AWS Bedrock (obrigatório)
      - key: AWS_ACCESS_KEY_ID
        sync: false
      - key: AWS_SECRET_ACCESS_KEY
        sync: false
      - key: AWS_REGION
        value: us-west-2

      # Anthropic (alternativo)
      - key: ANTHROPIC_API_KEY
        sync: false

      # DataJud (consulta jurisprudência)
      - key: DATAJUD_ENABLED
        value: "true"
      - key: DATAJUD_API_KEY
        sync: false

      # ═══════════════════════════════════════════════════════════════
      # GOOGLE CUSTOM SEARCH API - CRÍTICO PARA JURISPRUDÊNCIA
      # ═══════════════════════════════════════════════════════════════
      # SEM ISSO: Busca trava 30+ segundos e falha
      # COM ISSO: Busca retorna em 300ms-2s com resultados reais
      # ═══════════════════════════════════════════════════════════════
      - key: GOOGLE_SEARCH_API_KEY
        sync: false
      - key: GOOGLE_SEARCH_CX
        sync: false

      # ═══════════════════════════════════════════════════════════════
      # PUPPETEER - BYPASS DE CLOUDFLARE EM TRIBUNAIS
      # ═══════════════════════════════════════════════════════════════
      # Permite scraping de ementas completas em TJGO, TJCE, TJBA, etc
      # Tribunais estaduais usam Cloudflare que bloqueia HTTP simples
      # ═══════════════════════════════════════════════════════════════
      - key: PUPPETEER_SKIP_CHROMIUM_DOWNLOAD
        value: "true"  # Não baixar - usar Chromium do sistema (Aptfile)
      - key: PUPPETEER_EXECUTABLE_PATH
        value: /usr/bin/chromium-browser  # Chromium instalado via Aptfile

      # Session Secret (auto-gerado)
      - key: SESSION_SECRET
        generateValue: true

      # PostgreSQL Database (Internal Database URL)
      - key: DATABASE_URL
        value: postgresql://rom_agent_user:faPSk0YSNlhyPfBYpri2RcK9XdRbaE8L@dpg-d5819bhr0fns73dmfsv0-a/rom_agent

      # Rate Limiter
      # AJUSTADO PARA CHUNKED UPLOAD: 500MB = 13 chunks = 13 requests
      # Permitir múltiplos uploads grandes simultâneos
      - key: RATE_LIMIT_PER_MINUTE
        value: 60  # 60 requests/min = 4 uploads de 500MB simultâneos
      - key: RATE_LIMIT_PER_HOUR
        value: 500  # ~30 uploads de 500MB por hora

      # ═══════════════════════════════════════════════════════════════
      # UPLOAD LIMITS - PRO PLAN (8GB RAM)
      # Suporta 10+ usuários simultâneos com arquivos até 1GB
      # ═══════════════════════════════════════════════════════════════
      - key: MAX_BODY_SIZE
        value: 1100mb  # Aumentado para suportar arquivos até 1GB
      - key: MAX_FILE_SIZE
        value: 1000mb  # Limite de 1GB por arquivo
      - key: REQUEST_TIMEOUT
        value: 1800000  # 30 minutos - suporta uploads lentos de 500MB-1GB

    # ═══ HEALTH CHECK ═══
    healthCheckPath: /api/info

    # ═══ RECURSOS ═══
    # Disco persistente - 100 GB para múltiplos uploads simultâneos
    disk:
      mountPath: /var/data
      sizeGB: 100  # ✅ CORRIGIDO: 100 GB (10 usuários × 500 MB + processamento)

    # ═══ AUTO-DEPLOY ═══
    autoDeploy: true

    # ═══ DOMÍNIOS ═══
    domains:
      - iarom.com.br
      - www.iarom.com.br

  # ═══════════════════════════════════════════════════════════════
  # STAGING - Branch staging
  # ═══════════════════════════════════════════════════════════════
  - type: web
    name: rom-agent-staging
    runtime: node
    plan: standard  # ✅ 2GB RAM - suporta uploads de até 500MB
    branch: staging

    # ═══ BUILD ═══
    buildCommand: bash scripts/build-production.sh

    # ═══ START ═══
    # CRÍTICO: Iniciar servidor IMEDIATAMENTE para evitar port scan timeout
    # Frontend já foi buildado no buildCommand
    # Migrations rodam assíncronamente após servidor abrir porta
    startCommand: npm run web:enhanced

    # ═══ VARIÁVEIS DE AMBIENTE ═══
    envVars:
      # Node.js
      - key: NODE_ENV
        value: staging
      - key: NODE_VERSION
        value: 25.2.1

      # Porta (Render usa 10000)
      - key: PORT
        value: 10000

      # ✅ FORÇAR USO DO DISCO PERSISTENTE /var/data
      - key: RENDER
        value: "true"
      - key: UPLOAD_FOLDER
        value: /var/data/upload
      - key: EXTRACTED_FOLDER
        value: /var/data/extracted
      - key: PROCESSED_FOLDER
        value: /var/data/processed

      # AWS Bedrock (obrigatório)
      - key: AWS_ACCESS_KEY_ID
        sync: false
      - key: AWS_SECRET_ACCESS_KEY
        sync: false
      - key: AWS_REGION
        value: us-west-2

      # Anthropic (alternativo)
      - key: ANTHROPIC_API_KEY
        sync: false

      # DataJud (consulta jurisprudência)
      - key: DATAJUD_ENABLED
        value: "true"
      - key: DATAJUD_API_KEY
        sync: false

      # ═══════════════════════════════════════════════════════════════
      # GOOGLE CUSTOM SEARCH API - CRÍTICO PARA JURISPRUDÊNCIA
      # ═══════════════════════════════════════════════════════════════
      # SEM ISSO: Busca trava 30+ segundos e falha
      # COM ISSO: Busca retorna em 300ms-2s com resultados reais
      # ═══════════════════════════════════════════════════════════════
      - key: GOOGLE_SEARCH_API_KEY
        sync: false
      - key: GOOGLE_SEARCH_CX
        sync: false

      # ═══════════════════════════════════════════════════════════════
      # PUPPETEER - BYPASS DE CLOUDFLARE EM TRIBUNAIS
      # ═══════════════════════════════════════════════════════════════
      # Permite scraping de ementas completas em TJGO, TJCE, TJBA, etc
      # Tribunais estaduais usam Cloudflare que bloqueia HTTP simples
      # ═══════════════════════════════════════════════════════════════
      - key: PUPPETEER_SKIP_CHROMIUM_DOWNLOAD
        value: "true"  # Não baixar - usar Chromium do sistema (Aptfile)
      - key: PUPPETEER_EXECUTABLE_PATH
        value: /usr/bin/chromium-browser  # Chromium instalado via Aptfile

      # Session Secret (auto-gerado)
      - key: SESSION_SECRET
        generateValue: true

      # PostgreSQL Database (Internal Database URL)
      - key: DATABASE_URL
        value: postgresql://rom_agent_user:faPSk0YSNlhyPfBYpri2RcK9XdRbaE8L@dpg-d5819bhr0fns73dmfsv0-a/rom_agent

      # Database Schema (staging usa schema separado)
      - key: DATABASE_SCHEMA
        value: staging

      # Rate Limiter (mais permissivo para testes)
      - key: RATE_LIMIT_PER_MINUTE
        value: 60  # Mesmo que produção para testar chunked upload
      - key: RATE_LIMIT_PER_HOUR
        value: 500  # Mesmo que produção

      # ═══════════════════════════════════════════════════════════════
      # UPLOAD LIMITS - STAGING (Standard 2GB RAM - suficiente para testes)
      # ═══════════════════════════════════════════════════════════════
      - key: MAX_BODY_SIZE
        value: 1100mb  # Consistente com produção
      - key: MAX_FILE_SIZE
        value: 1000mb  # Consistente com produção
      - key: REQUEST_TIMEOUT
        value: 1800000  # 30 minutos - consistente com produção

    # ═══ HEALTH CHECK ═══
    healthCheckPath: /api/info

    # ═══ RECURSOS ═══
    # Disco persistente separado para staging
    disk:
      mountPath: /var/data
      sizeGB: 50  # ✅ 50 GB para staging (menor que produção, suficiente para testes)

    # ═══ AUTO-DEPLOY ═══
    autoDeploy: true
